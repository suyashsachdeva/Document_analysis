{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "from torch.utils.data import DataLoader\n",
    "from torchsummary import summary\n",
    "\n",
    "import cv2 \n",
    "import os \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.auto import trange "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = r\"C:\\Users\\suyash\\Desktop\\indoml\\train\\train\"\n",
    "csv = r\"C:\\Users\\suyash\\Desktop\\indoml\\train_labels.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH=64\n",
    "DATASIZE = 6400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91dcedd2bbf54eb98ddecc303e59f950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preprocessing Progress:   0%|                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datafile = pd.read_csv(csv).values\n",
    "xtrain = []\n",
    "ytrain = []\n",
    "preprocessing = trange(DATASIZE, desc=\"Preprocessing Progress\", unit=\"image\", ncols=1000)\n",
    "for i in preprocessing:\n",
    "    y = datafile[i, 1]\n",
    "    ytr = np.zeros(16, dtype=\"float32\")\n",
    "    ytr[y] = 1\n",
    "    x = cv2.cvtColor(cv2.resize(cv2.imread(DATA+\"/\"+str(i)+\".tif\"), (225, 300), interpolation=cv2.INTER_AREA), cv2.COLOR_RGB2GRAY)\n",
    "    x = (x/255)\n",
    "    xtrain.append(x)\n",
    "    ytrain.append(ytr)\n",
    "    \n",
    "X = np.array(xtrain, dtype=\"float32\").reshape(-1, 300, 225, 1)\n",
    "Y = np.array(ytrain, dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6400, 300, 225, 1), (6400, 16))"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suyash\\AppData\\Local\\Temp/ipykernel_1272/3592386148.py:7: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  xtrain = np.array([xtr for xtr in xtrain])\n",
      "C:\\Users\\suyash\\AppData\\Local\\Temp/ipykernel_1272/3592386148.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  xtrain = np.array([xtr for xtr in xtrain])\n",
      "C:\\Users\\suyash\\AppData\\Local\\Temp/ipykernel_1272/3592386148.py:8: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  ytrain = np.array([ytr for ytr in ytrain])\n",
      "C:\\Users\\suyash\\AppData\\Local\\Temp/ipykernel_1272/3592386148.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  ytrain = np.array([ytr for ytr in ytrain])\n"
     ]
    }
   ],
   "source": [
    "xtrain = torch.from_numpy(X)\n",
    "ytrain = torch.from_numpy(Y)\n",
    "\n",
    "xtrain = DataLoader(xtrain, batch_size=BATCH)\n",
    "ytrain = DataLoader(ytrain, batch_size=BATCH)\n",
    "\n",
    "xtrain = np.array([xtr for xtr in xtrain])\n",
    "ytrain = np.array([ytr for ytr in ytrain])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResConvBlock(nn.Module):\n",
    "    def __init__(self, filter, kernel=3):\n",
    "        super(ResConvBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(filter, filter, kernel)\n",
    "        self.conv2 = nn.Conv2d(filter, filter, kernel)\n",
    "        self.pad = nn.ZeroPad2d(1)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.norm1 = nn.BatchNorm2d(filter)\n",
    "        self.norm2 = nn.BatchNorm2d(filter)\n",
    "        self.lrelu = nn.LeakyReLU(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        s = x\n",
    "        x = self.lrelu(self.norm1(self.pad(self.conv1(x))))\n",
    "        x = self.lrelu(self.norm2(self.pad(self.conv2(x)))+s)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBottleNeck(nn.Module):\n",
    "    def __init__(self, infilter, outfilter, kernel=3):\n",
    "        super(ResBottleNeck, self).__init__()\n",
    "        self.conv0 = nn.Conv2d(infilter, infilter, 1)\n",
    "        self.conv2 = nn.Conv2d(infilter, outfilter, 1)\n",
    "        self.conv1 = nn.Conv2d(infilter, infilter, kernel, stride=2)\n",
    "        self.conv = nn.Conv2d(infilter, outfilter, kernel, stride=2)\n",
    "        self.pad = nn.ZeroPad2d(1)\n",
    "        self.norm0 = nn.BatchNorm2d(infilter)\n",
    "        self.norm1 = nn.BatchNorm2d(infilter)\n",
    "        self.norm2 = nn.BatchNorm2d(outfilter)\n",
    "        self.norm = nn.BatchNorm2d(outfilter)\n",
    "        self.lrelu = nn.LeakyReLU(0.1)\n",
    "        # self.pool = nn.MaxPool2d(2,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        s = x\n",
    "        x = self.lrelu(self.norm0(self.conv0(x)))\n",
    "        x = self.lrelu(self.norm1(self.pad(self.conv1(x))))\n",
    "        x = self.lrelu(self.norm2(self.conv2(x)))\n",
    "        s = self.lrelu(self.norm(self.pad(self.conv(s))))\n",
    "        x = x+s\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, infilter, outfilter, kernel=3):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv0 = ResConvBlock(infilter)\n",
    "        self.conv1 = ResConvBlock(infilter)\n",
    "        self.conv2 = ResConvBlock(infilter)\n",
    "        self.conv3 = ResConvBlock(infilter)\n",
    "\n",
    "        self.conv = ResBottleNeck(infilter, outfilter)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(self.conv3(self.conv2((self.conv1(self.conv0(x))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StartBlock(nn.Module):\n",
    "    def __init__(self, filter):\n",
    "        super(StartBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, filter, 7, stride=2)\n",
    "        # self.conv2 = nn.Conv2d(filter//2, filter, 5, stride=2)\n",
    "\n",
    "        self.norm1 = nn.BatchNorm2d(filter)\n",
    "        # self.norm2 = nn.BatchNorm2d(filter)\n",
    "\n",
    "        self.lrelu = nn.LeakyReLU(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lrelu(self.norm1(self.conv1(x)))\n",
    "        return x #self.lrelu(self.norm2(self.conv2(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMaxpool(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return F.avg_pool2d(x, kernel_size=x.size()[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, filter=16, ndim=256, outclass=16):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.res0 = StartBlock(filter)\n",
    "        self.res1 = ResBlock(filter, filter*2)\n",
    "        self.res2 = ResBlock(filter*2, filter*4)\n",
    "        self.res3 = ResBlock(filter*4, filter*8)\n",
    "        self.res4 = ResBlock(filter*8, filter*16)\n",
    "        self.res5 = ResBlock(filter*16, filter*32)\n",
    "        self.res6 = ResBlock(filter*32, filter*64)\n",
    "\n",
    "        self.avgpool = GMaxpool()\n",
    "        self.flat = nn.Flatten()\n",
    "\n",
    "        self.dense1 = nn.Linear(1024, ndim)\n",
    "        self.dense2 = nn.Linear(ndim, outclass)\n",
    "        self.drop = nn.Dropout2d(0.2)\n",
    "        self.lrelu = nn.LeakyReLU(0.2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.res6(self.res5(self.res4(self.res3(self.res2(self.res1(self.res0(x)))))))\n",
    "        x = self.flat(self.avgpool(x))\n",
    "        return self.softmax(self.dense2(self.lrelu(self.drop(self.dense1(x)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### labels --> one-hot \n",
    "one_hot = torch.nn.functional.one_hot(target)\n",
    "#### one-hot --> labels\n",
    "labels_again = torch.argmax(one_hot, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 147, 110]             800\n",
      "       BatchNorm2d-2         [-1, 16, 147, 110]              32\n",
      "         LeakyReLU-3         [-1, 16, 147, 110]               0\n",
      "        StartBlock-4         [-1, 16, 147, 110]               0\n",
      "            Conv2d-5         [-1, 16, 145, 108]           2,320\n",
      "         ZeroPad2d-6         [-1, 16, 147, 110]               0\n",
      "       BatchNorm2d-7         [-1, 16, 147, 110]              32\n",
      "         LeakyReLU-8         [-1, 16, 147, 110]               0\n",
      "            Conv2d-9         [-1, 16, 145, 108]           2,320\n",
      "        ZeroPad2d-10         [-1, 16, 147, 110]               0\n",
      "      BatchNorm2d-11         [-1, 16, 147, 110]              32\n",
      "        LeakyReLU-12         [-1, 16, 147, 110]               0\n",
      "     ResConvBlock-13         [-1, 16, 147, 110]               0\n",
      "           Conv2d-14         [-1, 16, 145, 108]           2,320\n",
      "        ZeroPad2d-15         [-1, 16, 147, 110]               0\n",
      "      BatchNorm2d-16         [-1, 16, 147, 110]              32\n",
      "        LeakyReLU-17         [-1, 16, 147, 110]               0\n",
      "           Conv2d-18         [-1, 16, 145, 108]           2,320\n",
      "        ZeroPad2d-19         [-1, 16, 147, 110]               0\n",
      "      BatchNorm2d-20         [-1, 16, 147, 110]              32\n",
      "        LeakyReLU-21         [-1, 16, 147, 110]               0\n",
      "     ResConvBlock-22         [-1, 16, 147, 110]               0\n",
      "           Conv2d-23         [-1, 16, 145, 108]           2,320\n",
      "        ZeroPad2d-24         [-1, 16, 147, 110]               0\n",
      "      BatchNorm2d-25         [-1, 16, 147, 110]              32\n",
      "        LeakyReLU-26         [-1, 16, 147, 110]               0\n",
      "           Conv2d-27         [-1, 16, 145, 108]           2,320\n",
      "        ZeroPad2d-28         [-1, 16, 147, 110]               0\n",
      "      BatchNorm2d-29         [-1, 16, 147, 110]              32\n",
      "        LeakyReLU-30         [-1, 16, 147, 110]               0\n",
      "     ResConvBlock-31         [-1, 16, 147, 110]               0\n",
      "           Conv2d-32         [-1, 16, 145, 108]           2,320\n",
      "        ZeroPad2d-33         [-1, 16, 147, 110]               0\n",
      "      BatchNorm2d-34         [-1, 16, 147, 110]              32\n",
      "        LeakyReLU-35         [-1, 16, 147, 110]               0\n",
      "           Conv2d-36         [-1, 16, 145, 108]           2,320\n",
      "        ZeroPad2d-37         [-1, 16, 147, 110]               0\n",
      "      BatchNorm2d-38         [-1, 16, 147, 110]              32\n",
      "        LeakyReLU-39         [-1, 16, 147, 110]               0\n",
      "     ResConvBlock-40         [-1, 16, 147, 110]               0\n",
      "           Conv2d-41         [-1, 16, 147, 110]             272\n",
      "      BatchNorm2d-42         [-1, 16, 147, 110]              32\n",
      "        LeakyReLU-43         [-1, 16, 147, 110]               0\n",
      "           Conv2d-44           [-1, 16, 73, 54]           2,320\n",
      "        ZeroPad2d-45           [-1, 16, 75, 56]               0\n",
      "      BatchNorm2d-46           [-1, 16, 75, 56]              32\n",
      "        LeakyReLU-47           [-1, 16, 75, 56]               0\n",
      "           Conv2d-48           [-1, 32, 75, 56]             544\n",
      "      BatchNorm2d-49           [-1, 32, 75, 56]              64\n",
      "        LeakyReLU-50           [-1, 32, 75, 56]               0\n",
      "           Conv2d-51           [-1, 32, 73, 54]           4,640\n",
      "        ZeroPad2d-52           [-1, 32, 75, 56]               0\n",
      "      BatchNorm2d-53           [-1, 32, 75, 56]              64\n",
      "        LeakyReLU-54           [-1, 32, 75, 56]               0\n",
      "    ResBottleNeck-55           [-1, 32, 75, 56]               0\n",
      "         ResBlock-56           [-1, 32, 75, 56]               0\n",
      "           Conv2d-57           [-1, 32, 73, 54]           9,248\n",
      "        ZeroPad2d-58           [-1, 32, 75, 56]               0\n",
      "      BatchNorm2d-59           [-1, 32, 75, 56]              64\n",
      "        LeakyReLU-60           [-1, 32, 75, 56]               0\n",
      "           Conv2d-61           [-1, 32, 73, 54]           9,248\n",
      "        ZeroPad2d-62           [-1, 32, 75, 56]               0\n",
      "      BatchNorm2d-63           [-1, 32, 75, 56]              64\n",
      "        LeakyReLU-64           [-1, 32, 75, 56]               0\n",
      "     ResConvBlock-65           [-1, 32, 75, 56]               0\n",
      "           Conv2d-66           [-1, 32, 73, 54]           9,248\n",
      "        ZeroPad2d-67           [-1, 32, 75, 56]               0\n",
      "      BatchNorm2d-68           [-1, 32, 75, 56]              64\n",
      "        LeakyReLU-69           [-1, 32, 75, 56]               0\n",
      "           Conv2d-70           [-1, 32, 73, 54]           9,248\n",
      "        ZeroPad2d-71           [-1, 32, 75, 56]               0\n",
      "      BatchNorm2d-72           [-1, 32, 75, 56]              64\n",
      "        LeakyReLU-73           [-1, 32, 75, 56]               0\n",
      "     ResConvBlock-74           [-1, 32, 75, 56]               0\n",
      "           Conv2d-75           [-1, 32, 73, 54]           9,248\n",
      "        ZeroPad2d-76           [-1, 32, 75, 56]               0\n",
      "      BatchNorm2d-77           [-1, 32, 75, 56]              64\n",
      "        LeakyReLU-78           [-1, 32, 75, 56]               0\n",
      "           Conv2d-79           [-1, 32, 73, 54]           9,248\n",
      "        ZeroPad2d-80           [-1, 32, 75, 56]               0\n",
      "      BatchNorm2d-81           [-1, 32, 75, 56]              64\n",
      "        LeakyReLU-82           [-1, 32, 75, 56]               0\n",
      "     ResConvBlock-83           [-1, 32, 75, 56]               0\n",
      "           Conv2d-84           [-1, 32, 73, 54]           9,248\n",
      "        ZeroPad2d-85           [-1, 32, 75, 56]               0\n",
      "      BatchNorm2d-86           [-1, 32, 75, 56]              64\n",
      "        LeakyReLU-87           [-1, 32, 75, 56]               0\n",
      "           Conv2d-88           [-1, 32, 73, 54]           9,248\n",
      "        ZeroPad2d-89           [-1, 32, 75, 56]               0\n",
      "      BatchNorm2d-90           [-1, 32, 75, 56]              64\n",
      "        LeakyReLU-91           [-1, 32, 75, 56]               0\n",
      "     ResConvBlock-92           [-1, 32, 75, 56]               0\n",
      "           Conv2d-93           [-1, 32, 75, 56]           1,056\n",
      "      BatchNorm2d-94           [-1, 32, 75, 56]              64\n",
      "        LeakyReLU-95           [-1, 32, 75, 56]               0\n",
      "           Conv2d-96           [-1, 32, 37, 27]           9,248\n",
      "        ZeroPad2d-97           [-1, 32, 39, 29]               0\n",
      "      BatchNorm2d-98           [-1, 32, 39, 29]              64\n",
      "        LeakyReLU-99           [-1, 32, 39, 29]               0\n",
      "          Conv2d-100           [-1, 64, 39, 29]           2,112\n",
      "     BatchNorm2d-101           [-1, 64, 39, 29]             128\n",
      "       LeakyReLU-102           [-1, 64, 39, 29]               0\n",
      "          Conv2d-103           [-1, 64, 37, 27]          18,496\n",
      "       ZeroPad2d-104           [-1, 64, 39, 29]               0\n",
      "     BatchNorm2d-105           [-1, 64, 39, 29]             128\n",
      "       LeakyReLU-106           [-1, 64, 39, 29]               0\n",
      "   ResBottleNeck-107           [-1, 64, 39, 29]               0\n",
      "        ResBlock-108           [-1, 64, 39, 29]               0\n",
      "          Conv2d-109           [-1, 64, 37, 27]          36,928\n",
      "       ZeroPad2d-110           [-1, 64, 39, 29]               0\n",
      "     BatchNorm2d-111           [-1, 64, 39, 29]             128\n",
      "       LeakyReLU-112           [-1, 64, 39, 29]               0\n",
      "          Conv2d-113           [-1, 64, 37, 27]          36,928\n",
      "       ZeroPad2d-114           [-1, 64, 39, 29]               0\n",
      "     BatchNorm2d-115           [-1, 64, 39, 29]             128\n",
      "       LeakyReLU-116           [-1, 64, 39, 29]               0\n",
      "    ResConvBlock-117           [-1, 64, 39, 29]               0\n",
      "          Conv2d-118           [-1, 64, 37, 27]          36,928\n",
      "       ZeroPad2d-119           [-1, 64, 39, 29]               0\n",
      "     BatchNorm2d-120           [-1, 64, 39, 29]             128\n",
      "       LeakyReLU-121           [-1, 64, 39, 29]               0\n",
      "          Conv2d-122           [-1, 64, 37, 27]          36,928\n",
      "       ZeroPad2d-123           [-1, 64, 39, 29]               0\n",
      "     BatchNorm2d-124           [-1, 64, 39, 29]             128\n",
      "       LeakyReLU-125           [-1, 64, 39, 29]               0\n",
      "    ResConvBlock-126           [-1, 64, 39, 29]               0\n",
      "          Conv2d-127           [-1, 64, 37, 27]          36,928\n",
      "       ZeroPad2d-128           [-1, 64, 39, 29]               0\n",
      "     BatchNorm2d-129           [-1, 64, 39, 29]             128\n",
      "       LeakyReLU-130           [-1, 64, 39, 29]               0\n",
      "          Conv2d-131           [-1, 64, 37, 27]          36,928\n",
      "       ZeroPad2d-132           [-1, 64, 39, 29]               0\n",
      "     BatchNorm2d-133           [-1, 64, 39, 29]             128\n",
      "       LeakyReLU-134           [-1, 64, 39, 29]               0\n",
      "    ResConvBlock-135           [-1, 64, 39, 29]               0\n",
      "          Conv2d-136           [-1, 64, 37, 27]          36,928\n",
      "       ZeroPad2d-137           [-1, 64, 39, 29]               0\n",
      "     BatchNorm2d-138           [-1, 64, 39, 29]             128\n",
      "       LeakyReLU-139           [-1, 64, 39, 29]               0\n",
      "          Conv2d-140           [-1, 64, 37, 27]          36,928\n",
      "       ZeroPad2d-141           [-1, 64, 39, 29]               0\n",
      "     BatchNorm2d-142           [-1, 64, 39, 29]             128\n",
      "       LeakyReLU-143           [-1, 64, 39, 29]               0\n",
      "    ResConvBlock-144           [-1, 64, 39, 29]               0\n",
      "          Conv2d-145           [-1, 64, 39, 29]           4,160\n",
      "     BatchNorm2d-146           [-1, 64, 39, 29]             128\n",
      "       LeakyReLU-147           [-1, 64, 39, 29]               0\n",
      "          Conv2d-148           [-1, 64, 19, 14]          36,928\n",
      "       ZeroPad2d-149           [-1, 64, 21, 16]               0\n",
      "     BatchNorm2d-150           [-1, 64, 21, 16]             128\n",
      "       LeakyReLU-151           [-1, 64, 21, 16]               0\n",
      "          Conv2d-152          [-1, 128, 21, 16]           8,320\n",
      "     BatchNorm2d-153          [-1, 128, 21, 16]             256\n",
      "       LeakyReLU-154          [-1, 128, 21, 16]               0\n",
      "          Conv2d-155          [-1, 128, 19, 14]          73,856\n",
      "       ZeroPad2d-156          [-1, 128, 21, 16]               0\n",
      "     BatchNorm2d-157          [-1, 128, 21, 16]             256\n",
      "       LeakyReLU-158          [-1, 128, 21, 16]               0\n",
      "   ResBottleNeck-159          [-1, 128, 21, 16]               0\n",
      "        ResBlock-160          [-1, 128, 21, 16]               0\n",
      "          Conv2d-161          [-1, 128, 19, 14]         147,584\n",
      "       ZeroPad2d-162          [-1, 128, 21, 16]               0\n",
      "     BatchNorm2d-163          [-1, 128, 21, 16]             256\n",
      "       LeakyReLU-164          [-1, 128, 21, 16]               0\n",
      "          Conv2d-165          [-1, 128, 19, 14]         147,584\n",
      "       ZeroPad2d-166          [-1, 128, 21, 16]               0\n",
      "     BatchNorm2d-167          [-1, 128, 21, 16]             256\n",
      "       LeakyReLU-168          [-1, 128, 21, 16]               0\n",
      "    ResConvBlock-169          [-1, 128, 21, 16]               0\n",
      "          Conv2d-170          [-1, 128, 19, 14]         147,584\n",
      "       ZeroPad2d-171          [-1, 128, 21, 16]               0\n",
      "     BatchNorm2d-172          [-1, 128, 21, 16]             256\n",
      "       LeakyReLU-173          [-1, 128, 21, 16]               0\n",
      "          Conv2d-174          [-1, 128, 19, 14]         147,584\n",
      "       ZeroPad2d-175          [-1, 128, 21, 16]               0\n",
      "     BatchNorm2d-176          [-1, 128, 21, 16]             256\n",
      "       LeakyReLU-177          [-1, 128, 21, 16]               0\n",
      "    ResConvBlock-178          [-1, 128, 21, 16]               0\n",
      "          Conv2d-179          [-1, 128, 19, 14]         147,584\n",
      "       ZeroPad2d-180          [-1, 128, 21, 16]               0\n",
      "     BatchNorm2d-181          [-1, 128, 21, 16]             256\n",
      "       LeakyReLU-182          [-1, 128, 21, 16]               0\n",
      "          Conv2d-183          [-1, 128, 19, 14]         147,584\n",
      "       ZeroPad2d-184          [-1, 128, 21, 16]               0\n",
      "     BatchNorm2d-185          [-1, 128, 21, 16]             256\n",
      "       LeakyReLU-186          [-1, 128, 21, 16]               0\n",
      "    ResConvBlock-187          [-1, 128, 21, 16]               0\n",
      "          Conv2d-188          [-1, 128, 19, 14]         147,584\n",
      "       ZeroPad2d-189          [-1, 128, 21, 16]               0\n",
      "     BatchNorm2d-190          [-1, 128, 21, 16]             256\n",
      "       LeakyReLU-191          [-1, 128, 21, 16]               0\n",
      "          Conv2d-192          [-1, 128, 19, 14]         147,584\n",
      "       ZeroPad2d-193          [-1, 128, 21, 16]               0\n",
      "     BatchNorm2d-194          [-1, 128, 21, 16]             256\n",
      "       LeakyReLU-195          [-1, 128, 21, 16]               0\n",
      "    ResConvBlock-196          [-1, 128, 21, 16]               0\n",
      "          Conv2d-197          [-1, 128, 21, 16]          16,512\n",
      "     BatchNorm2d-198          [-1, 128, 21, 16]             256\n",
      "       LeakyReLU-199          [-1, 128, 21, 16]               0\n",
      "          Conv2d-200           [-1, 128, 10, 7]         147,584\n",
      "       ZeroPad2d-201           [-1, 128, 12, 9]               0\n",
      "     BatchNorm2d-202           [-1, 128, 12, 9]             256\n",
      "       LeakyReLU-203           [-1, 128, 12, 9]               0\n",
      "          Conv2d-204           [-1, 256, 12, 9]          33,024\n",
      "     BatchNorm2d-205           [-1, 256, 12, 9]             512\n",
      "       LeakyReLU-206           [-1, 256, 12, 9]               0\n",
      "          Conv2d-207           [-1, 256, 10, 7]         295,168\n",
      "       ZeroPad2d-208           [-1, 256, 12, 9]               0\n",
      "     BatchNorm2d-209           [-1, 256, 12, 9]             512\n",
      "       LeakyReLU-210           [-1, 256, 12, 9]               0\n",
      "   ResBottleNeck-211           [-1, 256, 12, 9]               0\n",
      "        ResBlock-212           [-1, 256, 12, 9]               0\n",
      "          Conv2d-213           [-1, 256, 10, 7]         590,080\n",
      "       ZeroPad2d-214           [-1, 256, 12, 9]               0\n",
      "     BatchNorm2d-215           [-1, 256, 12, 9]             512\n",
      "       LeakyReLU-216           [-1, 256, 12, 9]               0\n",
      "          Conv2d-217           [-1, 256, 10, 7]         590,080\n",
      "       ZeroPad2d-218           [-1, 256, 12, 9]               0\n",
      "     BatchNorm2d-219           [-1, 256, 12, 9]             512\n",
      "       LeakyReLU-220           [-1, 256, 12, 9]               0\n",
      "    ResConvBlock-221           [-1, 256, 12, 9]               0\n",
      "          Conv2d-222           [-1, 256, 10, 7]         590,080\n",
      "       ZeroPad2d-223           [-1, 256, 12, 9]               0\n",
      "     BatchNorm2d-224           [-1, 256, 12, 9]             512\n",
      "       LeakyReLU-225           [-1, 256, 12, 9]               0\n",
      "          Conv2d-226           [-1, 256, 10, 7]         590,080\n",
      "       ZeroPad2d-227           [-1, 256, 12, 9]               0\n",
      "     BatchNorm2d-228           [-1, 256, 12, 9]             512\n",
      "       LeakyReLU-229           [-1, 256, 12, 9]               0\n",
      "    ResConvBlock-230           [-1, 256, 12, 9]               0\n",
      "          Conv2d-231           [-1, 256, 10, 7]         590,080\n",
      "       ZeroPad2d-232           [-1, 256, 12, 9]               0\n",
      "     BatchNorm2d-233           [-1, 256, 12, 9]             512\n",
      "       LeakyReLU-234           [-1, 256, 12, 9]               0\n",
      "          Conv2d-235           [-1, 256, 10, 7]         590,080\n",
      "       ZeroPad2d-236           [-1, 256, 12, 9]               0\n",
      "     BatchNorm2d-237           [-1, 256, 12, 9]             512\n",
      "       LeakyReLU-238           [-1, 256, 12, 9]               0\n",
      "    ResConvBlock-239           [-1, 256, 12, 9]               0\n",
      "          Conv2d-240           [-1, 256, 10, 7]         590,080\n",
      "       ZeroPad2d-241           [-1, 256, 12, 9]               0\n",
      "     BatchNorm2d-242           [-1, 256, 12, 9]             512\n",
      "       LeakyReLU-243           [-1, 256, 12, 9]               0\n",
      "          Conv2d-244           [-1, 256, 10, 7]         590,080\n",
      "       ZeroPad2d-245           [-1, 256, 12, 9]               0\n",
      "     BatchNorm2d-246           [-1, 256, 12, 9]             512\n",
      "       LeakyReLU-247           [-1, 256, 12, 9]               0\n",
      "    ResConvBlock-248           [-1, 256, 12, 9]               0\n",
      "          Conv2d-249           [-1, 256, 12, 9]          65,792\n",
      "     BatchNorm2d-250           [-1, 256, 12, 9]             512\n",
      "       LeakyReLU-251           [-1, 256, 12, 9]               0\n",
      "          Conv2d-252            [-1, 256, 5, 4]         590,080\n",
      "       ZeroPad2d-253            [-1, 256, 7, 6]               0\n",
      "     BatchNorm2d-254            [-1, 256, 7, 6]             512\n",
      "       LeakyReLU-255            [-1, 256, 7, 6]               0\n",
      "          Conv2d-256            [-1, 512, 7, 6]         131,584\n",
      "     BatchNorm2d-257            [-1, 512, 7, 6]           1,024\n",
      "       LeakyReLU-258            [-1, 512, 7, 6]               0\n",
      "          Conv2d-259            [-1, 512, 5, 4]       1,180,160\n",
      "       ZeroPad2d-260            [-1, 512, 7, 6]               0\n",
      "     BatchNorm2d-261            [-1, 512, 7, 6]           1,024\n",
      "       LeakyReLU-262            [-1, 512, 7, 6]               0\n",
      "   ResBottleNeck-263            [-1, 512, 7, 6]               0\n",
      "        ResBlock-264            [-1, 512, 7, 6]               0\n",
      "          Conv2d-265            [-1, 512, 5, 4]       2,359,808\n",
      "       ZeroPad2d-266            [-1, 512, 7, 6]               0\n",
      "     BatchNorm2d-267            [-1, 512, 7, 6]           1,024\n",
      "       LeakyReLU-268            [-1, 512, 7, 6]               0\n",
      "          Conv2d-269            [-1, 512, 5, 4]       2,359,808\n",
      "       ZeroPad2d-270            [-1, 512, 7, 6]               0\n",
      "     BatchNorm2d-271            [-1, 512, 7, 6]           1,024\n",
      "       LeakyReLU-272            [-1, 512, 7, 6]               0\n",
      "    ResConvBlock-273            [-1, 512, 7, 6]               0\n",
      "          Conv2d-274            [-1, 512, 5, 4]       2,359,808\n",
      "       ZeroPad2d-275            [-1, 512, 7, 6]               0\n",
      "     BatchNorm2d-276            [-1, 512, 7, 6]           1,024\n",
      "       LeakyReLU-277            [-1, 512, 7, 6]               0\n",
      "          Conv2d-278            [-1, 512, 5, 4]       2,359,808\n",
      "       ZeroPad2d-279            [-1, 512, 7, 6]               0\n",
      "     BatchNorm2d-280            [-1, 512, 7, 6]           1,024\n",
      "       LeakyReLU-281            [-1, 512, 7, 6]               0\n",
      "    ResConvBlock-282            [-1, 512, 7, 6]               0\n",
      "          Conv2d-283            [-1, 512, 5, 4]       2,359,808\n",
      "       ZeroPad2d-284            [-1, 512, 7, 6]               0\n",
      "     BatchNorm2d-285            [-1, 512, 7, 6]           1,024\n",
      "       LeakyReLU-286            [-1, 512, 7, 6]               0\n",
      "          Conv2d-287            [-1, 512, 5, 4]       2,359,808\n",
      "       ZeroPad2d-288            [-1, 512, 7, 6]               0\n",
      "     BatchNorm2d-289            [-1, 512, 7, 6]           1,024\n",
      "       LeakyReLU-290            [-1, 512, 7, 6]               0\n",
      "    ResConvBlock-291            [-1, 512, 7, 6]               0\n",
      "          Conv2d-292            [-1, 512, 5, 4]       2,359,808\n",
      "       ZeroPad2d-293            [-1, 512, 7, 6]               0\n",
      "     BatchNorm2d-294            [-1, 512, 7, 6]           1,024\n",
      "       LeakyReLU-295            [-1, 512, 7, 6]               0\n",
      "          Conv2d-296            [-1, 512, 5, 4]       2,359,808\n",
      "       ZeroPad2d-297            [-1, 512, 7, 6]               0\n",
      "     BatchNorm2d-298            [-1, 512, 7, 6]           1,024\n",
      "       LeakyReLU-299            [-1, 512, 7, 6]               0\n",
      "    ResConvBlock-300            [-1, 512, 7, 6]               0\n",
      "          Conv2d-301            [-1, 512, 7, 6]         262,656\n",
      "     BatchNorm2d-302            [-1, 512, 7, 6]           1,024\n",
      "       LeakyReLU-303            [-1, 512, 7, 6]               0\n",
      "          Conv2d-304            [-1, 512, 3, 2]       2,359,808\n",
      "       ZeroPad2d-305            [-1, 512, 5, 4]               0\n",
      "     BatchNorm2d-306            [-1, 512, 5, 4]           1,024\n",
      "       LeakyReLU-307            [-1, 512, 5, 4]               0\n",
      "          Conv2d-308           [-1, 1024, 5, 4]         525,312\n",
      "     BatchNorm2d-309           [-1, 1024, 5, 4]           2,048\n",
      "       LeakyReLU-310           [-1, 1024, 5, 4]               0\n",
      "          Conv2d-311           [-1, 1024, 3, 2]       4,719,616\n",
      "       ZeroPad2d-312           [-1, 1024, 5, 4]               0\n",
      "     BatchNorm2d-313           [-1, 1024, 5, 4]           2,048\n",
      "       LeakyReLU-314           [-1, 1024, 5, 4]               0\n",
      "   ResBottleNeck-315           [-1, 1024, 5, 4]               0\n",
      "        ResBlock-316           [-1, 1024, 5, 4]               0\n",
      "        GMaxpool-317           [-1, 1024, 1, 1]               0\n",
      "         Flatten-318                 [-1, 1024]               0\n",
      "          Linear-319                  [-1, 256]         262,400\n",
      "       Dropout2d-320                  [-1, 256]               0\n",
      "       LeakyReLU-321                  [-1, 256]               0\n",
      "          Linear-322                   [-1, 16]           4,112\n",
      "         Softmax-323                   [-1, 16]               0\n",
      "================================================================\n",
      "Total params: 35,952,560\n",
      "Trainable params: 35,952,560\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.26\n",
      "Forward/backward pass size (MB): 196.61\n",
      "Params size (MB): 137.15\n",
      "Estimated Total Size (MB): 334.02\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = ResNet()\n",
    "summary(model, (1, 300,225))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "decay = 1\n",
    "epochs = 1\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Categorical Cross ENtropy`</br>\n",
    "Input: (N,C) where C = number of classes\n",
    "Target: (N) where each value is 0 <= targets[i] <= C-1\n",
    "Output: scalar. If reduce is False, then (N) instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "347ab2125e3a4bfd8322d8ea1f2e0f0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "\tTraining: 0/100 steps || Loss: NaNaN || Step Loss: NaNaN || Progress:   0%|                                  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1272/2042934033.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mxtr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mytr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mytrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mypred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBATCH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m225\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mypred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mytr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mlss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlss\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\suyash\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1272/3769892461.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mres6\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mres5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mres4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mres3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mres2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mres1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mres0\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\suyash\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1272/249674591.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv0\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\suyash\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1272/2211752973.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm0\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv0\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\suyash\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\suyash\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunning_mean\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunning_var\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m         return F.batch_norm(\n\u001b[0m\u001b[0;32m    136\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[1;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\suyash\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2147\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2149\u001b[1;33m     return torch.batch_norm(\n\u001b[0m\u001b[0;32m   2150\u001b[0m         \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2151\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "steps = len(xtrain)\n",
    "for epoch in range(epochs):\n",
    "    lss = 0\n",
    "    learning_rate = learning_rate/(epoch*decay+1)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    train = trange(steps, desc=f\"\\tTraining: 0/{steps} steps || Loss: NaNaN || Step Loss: NaNaN || Progress\", unit=\"steps\", ncols=1000)\n",
    "    for c in train:\n",
    "        xtr = xtrain[c]\n",
    "        ytr = ytrain[c]\n",
    "        ypred = model(xtr.reshape(BATCH, 1, 300, 225))\n",
    "        loss = criterion(ypred.reshape(-1,16), torch.argmax(ytr.reshape(-1,16), dim=1))\n",
    "        lss = lss + loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train.set_description(f\"\\tTraining: {c+1}/{steps} steps || Loss: {lss/(c+1):.4f} || Step Loss: {loss:.4f} || Progress\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cabed6552182076907bfdc495182d8bb0133da97d0d21fa33aa63cdbe2263e8f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
