{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch and OpenCV for Deep Learning and Image Processing\n",
    "This notebook demonstrates how to set up and use PyTorch for deep learning and OpenCV for image processing. It includes:\n",
    "- Loading and processing images.\n",
    "- Building simple and complex neural networks.\n",
    "- Visualizing progress with TQDM.\n",
    "- Summarizing models with `torchsummary`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for neural networks, image processing, and data handling\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchsummary import summary\n",
    "\n",
    "import cv2  # For image processing\n",
    "import os  # For file handling\n",
    "import pandas as pd  # For data manipulation\n",
    "import numpy as np  # For numerical operations\n",
    "import matplotlib.pyplot as plt  # For visualization\n",
    "\n",
    "from tqdm.auto import trange  # For progress bars in loops\n",
    "\n",
    "# Enable inline plotting for Jupyter Notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = r\"train_data\"\n",
    "CSV_PATH = r\"csv_path\"\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "DATASIZE = 6400\n",
    "NUM_CLASSES = 16\n",
    "IMAGE_WIDTH = 224\n",
    "IMAGE_HEIGHT = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Data for Model Training\n",
    "\n",
    "This section of the notebook preprocesses image data for training a deep learning model. The preprocessing involves:\n",
    "\n",
    "1. **Loading the Data**: Reading the dataset from a CSV file, which contains labels and metadata about the images.\n",
    "2. **One-Hot Encoding Labels**: Converting the numeric class labels into one-hot encoded vectors.\n",
    "3. **Resizing and Normalizing Images**:\n",
    "   - Each image is resized to a standard size of 225x300 pixels.\n",
    "   - Converted to grayscale to reduce complexity and focus on intensity values.\n",
    "   - Normalized to have pixel values between 0 and 1 for faster convergence during training.\n",
    "4. **Storing Preprocessed Data**: Preparing the data as NumPy arrays for model training.\n",
    "\n",
    "The processed data is stored in:\n",
    "- `X`: A NumPy array containing the image data.\n",
    "- `Y`: A NumPy array containing the one-hot encoded labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datafile\n",
    "datafile = pd.read_csv(CSV_PATH).values\n",
    "\n",
    "# Initialize lists for storing processed data\n",
    "x_train = []  # For storing image data\n",
    "y_train = []  # For storing one-hot encoded labels\n",
    "\n",
    "# Progress bar for preprocessing\n",
    "preprocessing = trange(DATASIZE, desc=\"Preprocessing Progress\", unit=\"image\", ncols=100)\n",
    "\n",
    "for i in preprocessing:\n",
    "    # Process the label\n",
    "    label = datafile[i, 1]  # Assuming the second column contains class labels\n",
    "    y_one_hot = np.zeros(NUM_CLASSES, dtype=\"float32\")\n",
    "    y_one_hot[label] = 1  # One-hot encoding the label\n",
    "\n",
    "    # Process the image\n",
    "    image_path = f\"{DATASET_PATH}/{i}.tif\"  # Construct the image path\n",
    "    image = cv2.imread(image_path)  # Read the image\n",
    "    if image is None:\n",
    "        print(f\"Warning: Image {image_path} could not be loaded.\")\n",
    "        continue\n",
    "\n",
    "    image_resized = cv2.resize(image, (IMAGE_WIDTH, IMAGE_HEIGHT), interpolation=cv2.INTER_AREA)  # Resize the image\n",
    "    image_gray = cv2.cvtColor(image_resized, cv2.COLOR_RGB2GRAY)  # Convert to grayscale\n",
    "    image_normalized = image_gray / 255.0  # Normalize pixel values to [0, 1]\n",
    "\n",
    "    # Append processed data to lists\n",
    "    x_train.append(image_normalized)\n",
    "    y_train.append(y_one_hot)\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "X = np.array(x_train, dtype=\"float32\").reshape(-1, IMAGE_HEIGHT, IMAGE_WIDTH, 1)  # Reshape to include channel dimension\n",
    "Y = np.array(y_train, dtype=\"float32\")\n",
    "\n",
    "print(f\"Preprocessed data shapes: X={X.shape}, Y={Y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Preprocessed Data to PyTorch Tensors and DataLoaders\n",
    "\n",
    "This section performs the following operations:\n",
    "\n",
    "1. **Convert NumPy Arrays to PyTorch Tensors**:\n",
    "   - The preprocessed data stored in `X` and `Y` (NumPy arrays) is converted to PyTorch tensors using `torch.from_numpy`.\n",
    "   - This is necessary because PyTorch models require tensor inputs.\n",
    "\n",
    "2. **Create PyTorch DataLoaders**:\n",
    "   - `DataLoader` is a utility provided by PyTorch to batch and shuffle the data for training.\n",
    "   - The `batch_size` parameter specifies the number of samples per batch, enabling efficient training on large datasets.\n",
    "\n",
    "3. **Batch Data Extraction**:\n",
    "   - Convert the batched tensors back to NumPy arrays for further processing or visualization.\n",
    "   - This step extracts all batches into single NumPy arrays using list comprehensions.\n",
    "\n",
    "This step ensures the data is efficiently prepared for model training while leveraging the advantages of PyTorch's DataLoader.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Convert NumPy arrays to PyTorch tensors\n",
    "x_train_tensor = torch.from_numpy(X)\n",
    "y_train_tensor = torch.from_numpy(Y)\n",
    "\n",
    "# Step 2: Create TensorDataset for PyTorch DataLoader\n",
    "dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "\n",
    "# Step 3: Create DataLoaders for batching\n",
    "data_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Step 4: Extract batches into NumPy arrays for further processing\n",
    "x_batches = []\n",
    "y_batches = []\n",
    "\n",
    "for batch in data_loader:\n",
    "    x_batch, y_batch = batch\n",
    "    x_batches.append(x_batch.numpy())\n",
    "    y_batches.append(y_batch.numpy())\n",
    "\n",
    "x_batches = np.array(x_batches)\n",
    "y_batches = np.array(y_batches)\n",
    "\n",
    "# Verify shapes\n",
    "print(f\"Shape of batched input data: {x_batches.shape}\")\n",
    "print(f\"Shape of batched labels: {y_batches.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResConvBlock(nn.Module):\n",
    "    def __init__(self, filter, kernel=3):\n",
    "        super(ResConvBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(filter, filter, kernel)\n",
    "        self.conv2 = nn.Conv2d(filter, filter, kernel)\n",
    "        self.pad = nn.ZeroPad2d(1)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.norm1 = nn.BatchNorm2d(filter)\n",
    "        self.norm2 = nn.BatchNorm2d(filter)\n",
    "        self.lrelu = nn.LeakyReLU(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        s = x\n",
    "        x = self.lrelu(self.norm1(self.pad(self.conv1(x))))\n",
    "        x = self.lrelu(self.norm2(self.pad(self.conv2(x)))+s)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBottleNeck(nn.Module):\n",
    "    def __init__(self, infilter, outfilter, kernel=3):\n",
    "        super(ResBottleNeck, self).__init__()\n",
    "        self.conv0 = nn.Conv2d(infilter, infilter, 1)\n",
    "        self.conv2 = nn.Conv2d(infilter, outfilter, 1)\n",
    "        self.conv1 = nn.Conv2d(infilter, infilter, kernel, stride=2)\n",
    "        self.conv = nn.Conv2d(infilter, outfilter, kernel, stride=2)\n",
    "        self.pad = nn.ZeroPad2d(1)\n",
    "        self.norm0 = nn.BatchNorm2d(infilter)\n",
    "        self.norm1 = nn.BatchNorm2d(infilter)\n",
    "        self.norm2 = nn.BatchNorm2d(outfilter)\n",
    "        self.norm = nn.BatchNorm2d(outfilter)\n",
    "        self.lrelu = nn.LeakyReLU(0.1)\n",
    "        # self.pool = nn.MaxPool2d(2,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        s = x\n",
    "        x = self.lrelu(self.norm0(self.conv0(x)))\n",
    "        x = self.lrelu(self.norm1(self.pad(self.conv1(x))))\n",
    "        x = self.lrelu(self.norm2(self.conv2(x)))\n",
    "        s = self.lrelu(self.norm(self.pad(self.conv(s))))\n",
    "        x = x+s\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, infilter, outfilter, kernel=3):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv0 = ResConvBlock(infilter)\n",
    "        self.conv1 = ResConvBlock(infilter)\n",
    "        self.conv2 = ResConvBlock(infilter)\n",
    "        self.conv3 = ResConvBlock(infilter)\n",
    "\n",
    "        self.conv = ResBottleNeck(infilter, outfilter)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(self.conv3(self.conv2((self.conv1(self.conv0(x))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StartBlock(nn.Module):\n",
    "    def __init__(self, filter):\n",
    "        super(StartBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, filter, 7, stride=2)\n",
    "        # self.conv2 = nn.Conv2d(filter//2, filter, 5, stride=2)\n",
    "\n",
    "        self.norm1 = nn.BatchNorm2d(filter)\n",
    "        # self.norm2 = nn.BatchNorm2d(filter)\n",
    "\n",
    "        self.lrelu = nn.LeakyReLU(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lrelu(self.norm1(self.conv1(x)))\n",
    "        return x #self.lrelu(self.norm2(self.conv2(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMaxpool(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return F.avg_pool2d(x, kernel_size=x.size()[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, filter=16, ndim=256, outclass=16):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.res0 = StartBlock(filter)\n",
    "        self.res1 = ResBlock(filter, filter*2)\n",
    "        self.res2 = ResBlock(filter*2, filter*4)\n",
    "        self.res3 = ResBlock(filter*4, filter*8)\n",
    "        self.res4 = ResBlock(filter*8, filter*16)\n",
    "        self.res5 = ResBlock(filter*16, filter*32)\n",
    "        self.res6 = ResBlock(filter*32, filter*64)\n",
    "\n",
    "        self.avgpool = GMaxpool()\n",
    "        self.flat = nn.Flatten()\n",
    "\n",
    "        self.dense1 = nn.Linear(1024, ndim)\n",
    "        self.dense2 = nn.Linear(ndim, outclass)\n",
    "        self.drop = nn.Dropout2d(0.2)\n",
    "        self.lrelu = nn.LeakyReLU(0.2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.res6(self.res5(self.res4(self.res3(self.res2(self.res1(self.res0(x)))))))\n",
    "        x = self.flat(self.avgpool(x))\n",
    "        return self.softmax(self.dense2(self.lrelu(self.drop(self.dense1(x)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### labels --> one-hot \n",
    "one_hot = torch.nn.functional.one_hot(target)\n",
    "#### one-hot --> labels\n",
    "labels_again = torch.argmax(one_hot, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet()\n",
    "summary(model, (1, 300,225))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "decay = 1\n",
    "epochs = 1\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Categorical Cross ENtropy`</br>\n",
    "Input: (N,C) where C = number of classes\n",
    "Target: (N) where each value is 0 <= targets[i] <= C-1\n",
    "Output: scalar. If reduce is False, then (N) instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = len(xtrain)\n",
    "for epoch in range(epochs):\n",
    "    lss = 0\n",
    "    learning_rate = learning_rate/(epoch*decay+1)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    train = trange(steps, desc=f\"\\tTraining: 0/{steps} steps || Loss: NaNaN || Step Loss: NaNaN || Progress\", unit=\"steps\", ncols=1000)\n",
    "    for c in train:\n",
    "        xtr = xtrain[c]\n",
    "        ytr = ytrain[c]\n",
    "        ypred = model(xtr.reshape(BATCH, 1, 300, 225))\n",
    "        loss = criterion(ypred.reshape(-1,16), torch.argmax(ytr.reshape(-1,16), dim=1))\n",
    "        lss = lss + loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train.set_description(f\"\\tTraining: {c+1}/{steps} steps || Loss: {lss/(c+1):.4f} || Step Loss: {loss:.4f} || Progress\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cabed6552182076907bfdc495182d8bb0133da97d0d21fa33aa63cdbe2263e8f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
